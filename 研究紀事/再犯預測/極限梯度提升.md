XGboost為 eXtreme Gradient Boosting簡稱，譯為「極限梯度提升」，以Gradient Boosting為基礎，結合Bagging和Boosting的優點，建立分類樹模型的過程中後面生成的分類樹修正前面分類樹犯錯的地方。Boosting方法將新的分類樹針對舊的分類樹預測不太好的部分做一些補強，最終將所有簡單的樹結合在一起成為最後的預測輸出。XGboost是採用特徵隨機取樣的技巧，和隨機森林一樣在生成每一棵樹的時候隨機抽取特徵。XGBoost演算法展現精確、效率、及可執行性的特性，因此成為近年來常用的機器學習方法。在Ozkan（2017）所發表的博士論文當中，使用了六個統計模型來研究囚犯再犯預測分類的效能。實驗結果發現，這六種方法所展現的效能差異不大，其中比較特別的是XGBoost具有最佳的測試準確率(0.778)、AUC數值(0.824)與F1-score(0.830)。目前 Kaggle 競賽中最常見到的算法，同時也是多數得獎者所使用的模型。這也是本計畫納入XGBoost進行再犯預測的原因。