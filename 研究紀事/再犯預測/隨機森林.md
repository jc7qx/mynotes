隨機森林（Random Forest, RF）是一個包含多個決策樹（DT）的分類器，RF可以結合成百上千的單一決策樹，每一個決策樹使用的資料向量隨機選取，決策樹中每一個決策點可以限制特徵屬性的數目，最後預測的結果可以由平均不同的決策樹的演算結果獲得。隨機森林訓練演算法把隨機抽樣的技術（bagging）應用到決策樹的應用中，bagging方法重複從訓練集中抽取後放回（Draw with Replacement）抽樣，訓練結束之後，對未知樣本x的預測可以通過對x上所有單個回歸樹的預測求平均來實現。然而，RF不只是將許多決策樹的結果取平均值，而是運用二個重要的概念，一是對訓練集隨機抽取資料向量，二是隨機選取資料向量的特徵屬性。決策樹訓練過程中，RF由訓練資料集中隨機選取資料點（即資料向量），抽樣的方法為「抽取後再放回」，又可稱為 bootstrapping，亦即在一次的RF建構中，有一些資料向量可能會被重複使用，此一作法的目的在訓練建構決策樹時使用不同的資料向量，雖然在建立每一個決策樹的變異較大，但訓練操作多顆樹時可以降低其結果的整體變異量。在利用RF執行預測時，是採取多顆樹的平均值，以上的過程可稱為bagging，又可稱為bootstrap aggregating。另一個重要的隨機抽樣概念為決定每一個決策樹決策分支點時只考慮部份的特徵屬性。