---
publish: Electronic Markets (2021) 31:685–695
authors: Christian Janiesch, Patrick Zschech, Kai Heinrich
URL: https://doi.org/10.1007/s12525-021-00475-2
---

### 簡介
* 人工智慧(AI)是一種模擬人類認知以解決複雜的問題，機器學習(ML)可視為人工智慧的一個子領域，是可用於電腦運作方式以解釋及表示人類知識(Knoledge)。
* ML可從案例或實際觀察資料中自動地學習有意義的關係與模式，根據ML來實現AI應用，可以找到一個分析模型用以產生預測、規則、答案、及建議...等結果。
* 在ML的發展過程中，類神經網路(ANN)模型開發成為ML的有效的學習模型，ANN模型的技術已建構成深度學習(DL)技術領域。

### AI技術領域
| AI 功能                |   AI 方法                   |
|--------------------|-----------------------|
| 知識表示法          | 案例推理系統                                |
| 推理                     | 規則庫系統                                |
| 規劃                     | 基因演算法                                |
| 了解環境              | 模糊理論                                |
| 溝通                     |    多代理人系統                             |

### 機器學習
#machinrLearning 
機器學習演算法可以重覆地經由問題相關的訓練資料學習，使電腦能夠找出隱藏的複雜規則，特別適用於高維度的應用問題，如分類、回歸、或分群...等。機器學習演算法已經成果的應用在詐欺偵測、信用卡額度、語音及影像辨識、或自然語言處理(NLP)等領域。根據問題種類與可用的資料，

ML可概分為三類
* 監督式學習 (Supervised Learning)
	#supervisedlearning
   監督式學習的訓練資料需要輸入資料及輸出資料，輸入資料可視為影響輸出的因子值，相對應每一組影響因子值，訓練資料必須提供輸出目標值，可能是數值或是分類類別。可以函數型式看待監督式學習關聯，$y$ = $f({\hat{X}^d})$ ， $y$ 是輸出，$\hat{X}^d$ = ($x_1, x_2, x_3, ..., x_d$)是一組關鍵影響因子值。監督式學習的重點在於根據已知的訓練資料集(train data set)，包含輸入資料與輸入資料，找出$f(X)$，再依據測試資料集(test data set)來校正$f(X)$函數，以找出最合適的學習模型。監督式學習演算法適合用於迴歸分析或分類預測問題，例如運用產品特性、使用者評價、...預測產品的銷售量，或根據受保護管束人的特性、監所表現、刑案紀錄，來預測是否再犯？(二元分類問題)。實際可用於監督式學習的演算法包括迴歸分析、決策樹模型、及類神經網路模型。
* 非監督式學習 (Unsupervised Learning)
	#unsupervisedlearning
   非監督式學習問題中只有輸入資料，即每一觀察個案的特徵向量值，而沒有輸出結果或定義，因此非監督式學習的目的是找出特定的資訊結構，如針對個案資料是否可以產生分群現象(clustering)。在電子商務的應用中，根據購物者的購買行為可以將購物者自然分群，以了解其商務行為特性。在犯罪學領域，可以根據犯罪者的犯罪地點建立犯罪製圖，找出犯罪熱區，即為非監督式學習的應用之一。分群是一種資料探勘技術，演算法根據每一個資料個案特徵的相似性(Similarity)，找出資料的結構特性。非監督式學習常應用於分群、關聯性、與縮減維度。分群的方法可分為 K-means clustering、階層式分群、機率型分群模式等。
* 增強式學習 (Reinforcement Learning)
	#reinforcementlearning
   增強學習(RL)不僅能夠學習輸入與輸出關聯性，還能將一系列輸入映射到具有依賴性的輸出（例如，馬爾可夫決策過程）。增強學習存在於環境中的狀態和給定狀態下可能採取的行動的背景下。在學習過程中，演算法隨機探索某個環境中的狀態-動作（以構建狀態-動作表），然後在實踐中利用學習到的資訊利用狀態-動作獎勵為給定的環境選擇最佳動作導致某些目標狀態的狀態。增強學習的目標是讓機器自己學習。人類學習的過程中正確的學習步驟產生好的結果(reward)，否則將受到懲罰(punishment)，因此RL利用嘗試錯誤(trial and error)的方式來學習，朝向好的方向學習。在實際運作過程中需要建立一個策略(criterion)在每一步行動過程根據策略，避開不好的方向，趨向更好的方向。AlphaGo一種人工智慧的下棋系統，利用增強學習支持棋弈決策，是目前RL是成功的應用之一。



